# SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.

# SPDX-License-Identifier: Apache-2.0

import torch
import pytest
import math
from time import time
from loguru import logger
import ttnn
from tests.tt_eager.python_api_testing.sweep_tests.comparison_funcs import comp_equal, comp_pcc
from models.utility_functions import skip_for_grayskull
from tests.ttnn.unit_tests.operations.ccl.test_ccl_common import (
    create_and_load_sub_device_manager_with_fabric_interface,
    teardown_fabric_interface,
    create_global_semaphore_with_same_address,
)
from models.perf.benchmarking_utils import BenchmarkData, BenchmarkProfiler
from tracy import signpost

from tests.ttnn.utils_for_testing import assert_with_pcc

from tests.tt_eager.python_api_testing.unit_testing.misc.test_matmul_1d_gather_in0 import (
    num_cores_to_rectangle_grid,
    round_up,
)

LINEAR_TOPOLOGY = True
if LINEAR_TOPOLOGY:
    ALL_GATHER_TOPOLOGY = ttnn.Topology.Linear
    WRAP_MESH = False
else:
    ALL_GATHER_TOPOLOGY = ttnn.Topology.Ring
    WRAP_MESH = True


def check_mesh_tensor_alloc(tensor):
    device_tensors = ttnn.get_device_tensors(tensor)
    buffer_addr = device_tensors[0].buffer_address()

    if len(device_tensors) > 1:
        for i in range(1, len(device_tensors)):
            addr = device_tensors[i].buffer_address()
            if not addr == buffer_addr:
                return False
    return True


def run_all_reduce_qkv_heads_perf_impl(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    use_program_cache=False,
    enable_async=False,
    num_iters=1,
    warmup_iters=0,
    trace_mode=True,
    profiler=BenchmarkProfiler(),
):
    cluster_shape = (8, 4)

    create_persistent_fabric = True
    teardown_persistent_fabric = True
    enable_persistent_fabric = True

    if num_iters < 1:
        pytest.fail("num_iters must be >= 1")

    if not trace_mode:
        pytest.fail("Trace mode must be True")

    # Use Async mode based on test input config
    mesh_device.enable_async(enable_async)

    ##################################
    ##### Set up fabric stuff
    ##################################
    compute_grid_size = mesh_device.compute_with_storage_grid_size()
    ccl_sub_device_crs = ttnn.CoreRangeSet(
        {ttnn.CoreRange(ttnn.CoreCoord(0, 0), ttnn.CoreCoord(compute_grid_size.x - 1, compute_grid_size.y - 1))}
    )
    worker_sub_device = ttnn.SubDevice(
        [
            ccl_sub_device_crs,
        ]
    )
    worker_sub_device_id = ttnn.SubDeviceId(0)
    sub_device_stall_group = [worker_sub_device_id]
    if create_persistent_fabric:
        mesh_sub_device_manager_id = create_and_load_sub_device_manager_with_fabric_interface(
            mesh_device,
            [worker_sub_device],
            0,
            0,
            enable_persistent_fabric,
            wrap_fabric_around_mesh=WRAP_MESH,
            topology=ALL_GATHER_TOPOLOGY,
        )
        mesh_device.set_sub_device_stall_group(sub_device_stall_group)

    # create global semaphore handles
    ccl_semaphore_handles = [create_global_semaphore_with_same_address(mesh_device, ccl_sub_device_crs, 0)]

    logger.info(f"Output shape: {output_shape}")

    try:
        ##################################
        ##### Set up input tensors/configs
        ##################################

        ##### FF2 Case #####
        M, N = output_shape[2:]
        N_per_shard = round_up(math.ceil(N / input_num_cores), ttnn.TILE_SIZE)
        output_N_per_shard = round_up(math.ceil(N / output_num_cores), ttnn.TILE_SIZE)
        input_shape = [*cluster_shape, M, N]  # [8, 4, 32, 1280]
        intermediate_shape = [*input_shape[:-1], N * cluster_shape[cluster_axis]]

        CORE_RANGE = [(x, y) for y in range(compute_grid_size.y) for x in range(compute_grid_size.x)]
        core_range_set = ttnn.CoreRangeSet(
            [
                ttnn.CoreRange(
                    ttnn.CoreCoord(x, y),
                    ttnn.CoreCoord(x, y),
                )
                for x, y in CORE_RANGE[:input_num_cores]
            ]
        )
        input_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                core_range_set,
                [M, N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        output_core_range_set = ttnn.num_cores_to_corerangeset(output_num_cores, ttnn.CoreCoord(8, 5), row_wise=True)
        output_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        intermediate_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard * cluster_shape[cluster_axis]],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )

        logger.info(f"Input shape: {input_shape[2:]}, Padded shape: {[M, N_per_shard * input_num_cores]}")
        input_tensor = torch.randn(input_shape)

        # Prepare input tensors
        tt_qkv = ttnn.from_torch(
            input_tensor,
            device=mesh_device,
            layout=ttnn.TILE_LAYOUT,
            dtype=input_dtype,
            memory_config=input_mem_config,
            mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
        )  # [1, 1, 32, 1280]
        check_mesh_tensor_alloc(tt_qkv)

        intermediate_tensor = torch.zeros(intermediate_shape)
        tt_intermediate_tensors = [
            ttnn.from_torch(
                intermediate_tensor,
                device=mesh_device,
                layout=ttnn.TILE_LAYOUT,
                dtype=input_dtype,
                memory_config=intermediate_mem_config,
                mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
            )
        ]

        # Validate that the tensor is allocated in same location across devices
        check_mesh_tensor_alloc(tt_intermediate_tensors[0])

        # Select batch_offset with create_qkv_heads_decode instead of selection matmul
        batch_offset = [0, 8, 16, 24]
        batch_offset_tt_tensor = ttnn.as_tensor(
            torch.tensor(batch_offset, dtype=torch.int32).reshape(4, 1),
            dtype=ttnn.int32,
            device=mesh_device,
            mesh_mapper=ttnn.ShardTensor2dMesh(
                mesh_device=mesh_device, dims=(None, 0), mesh_shape=list(mesh_device.shape)
            ),
            layout=ttnn.TILE_LAYOUT,
            memory_config=ttnn.DRAM_MEMORY_CONFIG,
        )

        ##################################
        ##### Run the op
        ##################################

        # Compile Run
        logger.info("Compiling model")

        tt_qkv_reduced = ttnn.experimental.all_reduce_async(
            tt_qkv,
            tt_intermediate_tensors[0],
            cluster_axis=cluster_axis,
            mesh_device=mesh_device,
            multi_device_global_semaphore=ccl_semaphore_handles[0],
            memory_config=output_mem_config,
            topology=ALL_GATHER_TOPOLOGY,
            num_links=num_links,
            subdevice_id=worker_sub_device_id,
        )  # [1, 1, 32, 1280]

        # Batch Slicing
        # 32 BS is split into 8 Mini BS across 4 devices
        ttnn.synchronize_device(mesh_device)

        (
            q_heads_pre_rot_1BQD,  # Shape([1, 8, 8, 128])
            k_heads_pre_rot_1BKD,  # Shape([1, 8, 1, 128])
            v_heads_1BKD,  # Shape([1, 8, 1, 128])
        ) = ttnn.experimental.nlp_create_qkv_heads_decode(
            tt_qkv_reduced,
            num_heads=8,
            num_kv_heads=1,
            memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
            overlap_qk_coregrid=False,
            batch_offset=batch_offset_tt_tensor,
            slice_size=8,
        )  # [1, 8, 8[32], 128], [1, 8, 1[32], 128], [1, 8, 1[32], 128]

        # After ConcatMesh2dToTensor
        # [1, 8, 8[32], 128] -> [8, 32, 8[32], 128]

        # Get non-distributed tensors
        q_non_distributed = ttnn.to_torch(
            q_heads_pre_rot_1BQD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        k_non_distributed = ttnn.to_torch(
            k_heads_pre_rot_1BKD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        v_non_distributed = ttnn.to_torch(
            v_heads_1BKD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )

        # Warm up runs
        logger.info("Capturing Warmup")

        print("Warmup iteration: ", warmup_iters)
        if warmup_iters > 0:
            trace_id_warmup = ttnn.begin_trace_capture(mesh_device, cq_id=0)
            for i in range(warmup_iters):
                tt_qkv_reduced = ttnn.experimental.all_reduce_async(
                    tt_qkv,
                    tt_intermediate_tensors[0],
                    cluster_axis=cluster_axis,
                    mesh_device=mesh_device,
                    multi_device_global_semaphore=ccl_semaphore_handles[0],
                    memory_config=output_mem_config,
                    topology=ALL_GATHER_TOPOLOGY,
                    num_links=num_links,
                    subdevice_id=worker_sub_device_id,
                )  # [1, 1, 32, 1280]

                # Batch Slicing
                # 32 BS is split into 8 Mini BS across 4 devices
                # ttnn.synchronize_device(mesh_device)

                (
                    q_heads_pre_rot_1BQD,  # Shape([1, 8, 8, 128])
                    k_heads_pre_rot_1BKD,  # Shape([1, 8, 1, 128])
                    v_heads_1BKD,  # Shape([1, 8, 1, 128])
                ) = ttnn.experimental.nlp_create_qkv_heads_decode(
                    tt_qkv_reduced,
                    num_heads=8,
                    num_kv_heads=1,
                    memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
                    overlap_qk_coregrid=False,
                    batch_offset=batch_offset_tt_tensor,
                    slice_size=8,
                )  # [1, 8, 8[32], 128], [1, 8, 1[32], 128], [1, 8, 1[32], 128]

            ttnn.end_trace_capture(mesh_device, trace_id_warmup, cq_id=0)
            ttnn.synchronize_device(mesh_device)

        # perf runs
        trace_id = ttnn.begin_trace_capture(mesh_device, cq_id=0)
        for i in range(num_iters):
            tt_qkv_reduced = ttnn.experimental.all_reduce_async(
                tt_qkv,
                tt_intermediate_tensors[0],
                cluster_axis=cluster_axis,
                mesh_device=mesh_device,
                multi_device_global_semaphore=ccl_semaphore_handles[0],
                memory_config=output_mem_config,
                topology=ALL_GATHER_TOPOLOGY,
                num_links=num_links,
                subdevice_id=worker_sub_device_id,
            )  # [1, 1, 32, 1280]

            # Batch Slicing
            # 32 BS is split into 8 Mini BS across 4 devices
            # ttnn.synchronize_device(mesh_device)

            (
                q_heads_pre_rot_1BQD,  # Shape([1, 8, 8, 128])
                k_heads_pre_rot_1BKD,  # Shape([1, 8, 1, 128])
                v_heads_1BKD,  # Shape([1, 8, 1, 128])
            ) = ttnn.experimental.nlp_create_qkv_heads_decode(
                tt_qkv_reduced,
                num_heads=8,
                num_kv_heads=1,
                memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
                overlap_qk_coregrid=False,
                batch_offset=batch_offset_tt_tensor,
                slice_size=8,
            )  # [1, 8, 8[32], 128], [1, 8, 1[32], 128], [1, 8, 1[32], 128]

        ttnn.end_trace_capture(mesh_device, trace_id, cq_id=0)
        ttnn.synchronize_device(mesh_device)

        # Run the op
        logger.info("Starting Trace perf test...")

        signpost("start")
        profiler.start("all-reduce-qkv-heads-trace")
        ttnn.execute_trace(mesh_device, trace_id, blocking=False)
        ttnn.release_trace(mesh_device, trace_id)
        ttnn.synchronize_device(mesh_device)
        profiler.end("all-reduce-qkv-heads-trace")

        signpost("stop")

        # input = [8, 4, 32, 1280]

        # reduced_input = [8, 32, 1280]
        reduced_input_tensor = input_tensor.sum(dim=1)

        # reduced_input_reshaped = [8, 32, 10, 128]
        reduced_input_tensor_reshaped = reduced_input_tensor.reshape(8, 32, 10, 128)

        # q_output = [8, 32, 8, 128]
        q_output_tensor = reduced_input_tensor_reshaped[:, :, :8, :]

        # k_output = [8, 32, 1, 128]
        k_output_tensor = reduced_input_tensor_reshaped[:, :, 8:9, :]

        # v_output = [8, 32, 1, 128]
        v_output_tensor = reduced_input_tensor_reshaped[:, :, 9:10, :]

        # Compare results
        assert_with_pcc(q_output_tensor, q_non_distributed, 0.9999)
        assert_with_pcc(k_output_tensor, k_non_distributed, 0.9999)
        assert_with_pcc(v_output_tensor, v_non_distributed, 0.9999)

    finally:
        if enable_persistent_fabric and teardown_persistent_fabric:
            mesh_device.reset_sub_device_stall_group()
            t1 = time()
            teardown_fabric_interface(mesh_device, wrap_fabric_around_mesh=WRAP_MESH, topology=ALL_GATHER_TOPOLOGY)
            t2 = time()
            logger.info(f"Teardown time: {t2 - t1}")


def run_all_reduce_qkv_heads_fuse_perf_impl(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    use_program_cache=False,
    enable_async=False,
    num_iters=1,
    warmup_iters=0,
    trace_mode=True,
    profiler=BenchmarkProfiler(),
):
    cluster_shape = (8, 4)

    create_persistent_fabric = True
    teardown_persistent_fabric = True
    enable_persistent_fabric = True

    if num_iters < 1:
        pytest.fail("num_iters must be >= 1")

    if not trace_mode:
        pytest.fail("Trace mode must be True")

    # Use Async mode based on test input config
    mesh_device.enable_async(enable_async)

    ##################################
    ##### Set up fabric stuff
    ##################################
    compute_grid_size = mesh_device.compute_with_storage_grid_size()
    ccl_sub_device_crs = ttnn.CoreRangeSet(
        {ttnn.CoreRange(ttnn.CoreCoord(0, 0), ttnn.CoreCoord(compute_grid_size.x - 1, compute_grid_size.y - 1))}
    )
    worker_sub_device = ttnn.SubDevice(
        [
            ccl_sub_device_crs,
        ]
    )
    worker_sub_device_id = ttnn.SubDeviceId(0)
    sub_device_stall_group = [worker_sub_device_id]
    if create_persistent_fabric:
        mesh_sub_device_manager_id = create_and_load_sub_device_manager_with_fabric_interface(
            mesh_device,
            [worker_sub_device],
            0,
            0,
            enable_persistent_fabric,
            wrap_fabric_around_mesh=WRAP_MESH,
            topology=ALL_GATHER_TOPOLOGY,
        )
        mesh_device.set_sub_device_stall_group(sub_device_stall_group)

    # create global semaphore handles
    ccl_semaphore_handles = [create_global_semaphore_with_same_address(mesh_device, ccl_sub_device_crs, 0)]

    logger.info(f"Output shape: {output_shape}")

    try:
        ##################################
        ##### Set up input tensors/configs
        ##################################

        ##### FF2 Case #####
        M, N = output_shape[2:]
        N_per_shard = round_up(math.ceil(N / input_num_cores), ttnn.TILE_SIZE)
        output_N_per_shard = round_up(math.ceil(N / output_num_cores), ttnn.TILE_SIZE)
        input_shape = [*cluster_shape, M, N]  # [8, 4, 32, 1280]
        intermediate_shape = [*input_shape[:-1], N * cluster_shape[cluster_axis]]

        CORE_RANGE = [(x, y) for y in range(compute_grid_size.y) for x in range(compute_grid_size.x)]
        core_range_set = ttnn.CoreRangeSet(
            [
                ttnn.CoreRange(
                    ttnn.CoreCoord(x, y),
                    ttnn.CoreCoord(x, y),
                )
                for x, y in CORE_RANGE[:input_num_cores]
            ]
        )
        input_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                core_range_set,
                [M, N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        output_core_range_set = ttnn.num_cores_to_corerangeset(output_num_cores, ttnn.CoreCoord(8, 5), row_wise=True)
        output_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        intermediate_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard * cluster_shape[cluster_axis]],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )

        logger.info(f"Input shape: {input_shape[2:]}, Padded shape: {[M, N_per_shard * input_num_cores]}")
        input_tensor = torch.randn(input_shape)

        # Prepare input tensors
        tt_qkv = ttnn.from_torch(
            input_tensor,
            device=mesh_device,
            layout=ttnn.TILE_LAYOUT,
            dtype=input_dtype,
            memory_config=input_mem_config,
            mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
        )  # [1, 1, 32, 1280]
        check_mesh_tensor_alloc(tt_qkv)

        intermediate_tensor = torch.zeros(intermediate_shape)
        tt_intermediate_tensors = [
            ttnn.from_torch(
                intermediate_tensor,
                device=mesh_device,
                layout=ttnn.TILE_LAYOUT,
                dtype=input_dtype,
                memory_config=intermediate_mem_config,
                mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
            )
        ]

        # Validate that the tensor is allocated in same location across devices
        check_mesh_tensor_alloc(tt_intermediate_tensors[0])

        # Select batch_offset with create_qkv_heads_decode instead of selection matmul
        batch_offset = [0, 8, 16, 24]
        batch_offset_tt_tensor = ttnn.as_tensor(
            torch.tensor(batch_offset, dtype=torch.int32).reshape(4, 1),
            dtype=ttnn.int32,
            device=mesh_device,
            mesh_mapper=ttnn.ShardTensor2dMesh(
                mesh_device=mesh_device, dims=(None, 0), mesh_shape=list(mesh_device.shape)
            ),
            layout=ttnn.TILE_LAYOUT,
            memory_config=ttnn.DRAM_MEMORY_CONFIG,
        )

        ##################################
        ##### Run the op
        ##################################

        # Compile Run
        logger.info("Compiling model")

        (
            tt_qkv_reduced,
            q_heads_pre_rot_1BQD,
            k_heads_pre_rot_1BKD,
            v_heads_1BKD,
        ) = ttnn.experimental.all_reduce_create_qkv_heads(
            tt_qkv,
            tt_intermediate_tensors[0],
            cluster_axis=cluster_axis,
            mesh_device=mesh_device,
            multi_device_global_semaphore=ccl_semaphore_handles[0],
            queue_id=0,
            num_heads=8,
            memory_config=output_mem_config,
            topology=ALL_GATHER_TOPOLOGY,
            num_links=num_links,
            subdevice_id=worker_sub_device_id,
            num_kv_heads=1,
            final_memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
            overlap_qk_coregrid=False,
            batch_offset=batch_offset_tt_tensor,
            slice_size=8,
        )

        # After ConcatMesh2dToTensor
        # [1, 8, 8[32], 128] -> [8, 32, 8[32], 128]

        # Get non-distributed tensors
        q_non_distributed = ttnn.to_torch(
            q_heads_pre_rot_1BQD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        k_non_distributed = ttnn.to_torch(
            k_heads_pre_rot_1BKD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        v_non_distributed = ttnn.to_torch(
            v_heads_1BKD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )

        # Warm up runs
        logger.info("Capturing Warmup")

        print("Warmup iteration: ", warmup_iters)
        if warmup_iters > 0:
            trace_id_warmup = ttnn.begin_trace_capture(mesh_device, cq_id=0)
            for i in range(warmup_iters):
                tt_qkv_reduced, q_dummy, k_dummy, v_dummy = ttnn.experimental.all_reduce_create_qkv_heads(
                    tt_qkv,
                    tt_intermediate_tensors[0],
                    cluster_axis=cluster_axis,
                    mesh_device=mesh_device,
                    multi_device_global_semaphore=ccl_semaphore_handles[0],
                    queue_id=0,
                    num_heads=8,
                    memory_config=output_mem_config,
                    topology=ALL_GATHER_TOPOLOGY,
                    num_links=num_links,
                    subdevice_id=worker_sub_device_id,
                    num_kv_heads=1,
                    final_memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
                    overlap_qk_coregrid=False,
                    batch_offset=batch_offset_tt_tensor,
                    slice_size=8,
                )

            ttnn.end_trace_capture(mesh_device, trace_id_warmup, cq_id=0)
            ttnn.synchronize_device(mesh_device)

        # perf runs
        trace_id = ttnn.begin_trace_capture(mesh_device, cq_id=0)
        for i in range(num_iters):
            tt_qkv_reduced, q_dummy, k_dummy, v_dummy = ttnn.experimental.all_reduce_create_qkv_heads(
                tt_qkv,
                tt_intermediate_tensors[0],
                cluster_axis=cluster_axis,
                mesh_device=mesh_device,
                multi_device_global_semaphore=ccl_semaphore_handles[0],
                queue_id=0,
                num_heads=8,
                memory_config=output_mem_config,
                topology=ALL_GATHER_TOPOLOGY,
                num_links=num_links,
                subdevice_id=worker_sub_device_id,
                num_kv_heads=1,
                final_memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
                overlap_qk_coregrid=False,
                batch_offset=batch_offset_tt_tensor,
                slice_size=8,
            )

        ttnn.end_trace_capture(mesh_device, trace_id, cq_id=0)
        ttnn.synchronize_device(mesh_device)

        # Run the op
        logger.info("Starting Trace perf test...")

        profiler.start("all-reduce-qkv-heads-trace-warmup")
        if warmup_iters > 0:
            ttnn.execute_trace(mesh_device, trace_id_warmup, blocking=False)
            ttnn.release_trace(mesh_device, trace_id_warmup)
            ttnn.synchronize_device(mesh_device)
        profiler.end("all-reduce-qkv-heads-trace-warmup")

        signpost("start")
        profiler.start("all-reduce-qkv-heads-trace")
        ttnn.execute_trace(mesh_device, trace_id, blocking=False)
        ttnn.release_trace(mesh_device, trace_id)
        ttnn.synchronize_device(mesh_device)
        profiler.end("all-reduce-qkv-heads-trace")

        signpost("stop")
        time_taken = profiler.get_duration("all-reduce-qkv-heads-trace") - profiler.get_duration(
            "all-reduce-qkv-heads-trace-warmup"
        )

        # input = [8, 4, 32, 1280]

        # reduced_input = [8, 32, 1280]
        reduced_input_tensor = input_tensor.sum(dim=1)

        # reduced_input_reshaped = [8, 32, 10, 128]
        reduced_input_tensor_reshaped = reduced_input_tensor.reshape(8, 32, 10, 128)

        # q_output = [8, 32, 8, 128]
        q_output_tensor = reduced_input_tensor_reshaped[:, :, :8, :]

        # k_output = [8, 32, 1, 128]
        k_output_tensor = reduced_input_tensor_reshaped[:, :, 8:9, :]

        # v_output = [8, 32, 1, 128]
        v_output_tensor = reduced_input_tensor_reshaped[:, :, 9:10, :]

        # Compare results
        assert_with_pcc(q_output_tensor, q_non_distributed, 0.9999)
        assert_with_pcc(k_output_tensor, k_non_distributed, 0.9999)
        assert_with_pcc(v_output_tensor, v_non_distributed, 0.9999)

    finally:
        if enable_persistent_fabric and teardown_persistent_fabric:
            mesh_device.reset_sub_device_stall_group()
            t1 = time()
            teardown_fabric_interface(mesh_device, wrap_fabric_around_mesh=WRAP_MESH, topology=ALL_GATHER_TOPOLOGY)
            t2 = time()
            logger.info(f"Teardown time: {t2 - t1}")


def run_all_reduce_qkv_heads_impl(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    enable_async=False,
):
    cluster_shape = (8, 4)

    create_persistent_fabric = True
    teardown_persistent_fabric = True
    enable_persistent_fabric = True

    # Use Async mode based on test input config
    mesh_device.enable_async(enable_async)

    ##################################
    ##### Set up fabric stuff
    ##################################
    compute_grid_size = mesh_device.compute_with_storage_grid_size()
    ccl_sub_device_crs = ttnn.CoreRangeSet(
        {ttnn.CoreRange(ttnn.CoreCoord(0, 0), ttnn.CoreCoord(compute_grid_size.x - 1, compute_grid_size.y - 1))}
    )
    worker_sub_device = ttnn.SubDevice(
        [
            ccl_sub_device_crs,
        ]
    )
    worker_sub_device_id = ttnn.SubDeviceId(0)
    sub_device_stall_group = [worker_sub_device_id]
    if create_persistent_fabric:
        mesh_sub_device_manager_id = create_and_load_sub_device_manager_with_fabric_interface(
            mesh_device,
            [worker_sub_device],
            0,
            0,
            enable_persistent_fabric,
            wrap_fabric_around_mesh=WRAP_MESH,
            topology=ALL_GATHER_TOPOLOGY,
        )
        mesh_device.set_sub_device_stall_group(sub_device_stall_group)

    # create global semaphore handles
    ccl_semaphore_handles = [create_global_semaphore_with_same_address(mesh_device, ccl_sub_device_crs, 0)]

    logger.info(f"Output shape: {output_shape}")

    try:
        ##################################
        ##### Set up input tensors/configs
        ##################################

        ##### FF2 Case #####
        M, N = output_shape[2:]
        N_per_shard = round_up(math.ceil(N / input_num_cores), ttnn.TILE_SIZE)
        output_N_per_shard = round_up(math.ceil(N / output_num_cores), ttnn.TILE_SIZE)
        input_shape = [*cluster_shape, M, N]  # [8, 4, 32, 1280]
        intermediate_shape = [*input_shape[:-1], N * cluster_shape[cluster_axis]]

        CORE_RANGE = [(x, y) for y in range(compute_grid_size.y) for x in range(compute_grid_size.x)]
        core_range_set = ttnn.CoreRangeSet(
            [
                ttnn.CoreRange(
                    ttnn.CoreCoord(x, y),
                    ttnn.CoreCoord(x, y),
                )
                for x, y in CORE_RANGE[:input_num_cores]
            ]
        )
        input_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                core_range_set,
                [M, N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        output_core_range_set = ttnn.num_cores_to_corerangeset(output_num_cores, ttnn.CoreCoord(8, 5), row_wise=True)
        output_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        intermediate_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard * cluster_shape[cluster_axis]],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )

        logger.info(f"Input shape: {input_shape[2:]}, Padded shape: {[M, N_per_shard * input_num_cores]}")
        input_tensor = torch.randn(input_shape)
        # input_tensor torch.Size([8, 4, 32, 1280])
        tt_qkv = ttnn.from_torch(
            input_tensor,
            device=mesh_device,
            layout=ttnn.TILE_LAYOUT,
            dtype=input_dtype,
            memory_config=input_mem_config,
            mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
        )  # [1, 1, 32, 1280]
        check_mesh_tensor_alloc(tt_qkv)

        intermediate_tensor = torch.zeros(intermediate_shape)
        tt_intermediate_tensors = [
            ttnn.from_torch(
                intermediate_tensor,
                device=mesh_device,
                layout=ttnn.TILE_LAYOUT,
                dtype=input_dtype,
                memory_config=intermediate_mem_config,
                mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
            )
        ]

        # Validate that the tensor is allocated in same location across devices
        check_mesh_tensor_alloc(tt_intermediate_tensors[0])

        # Select batch_offset with create_qkv_heads_decode instead of selection matmul
        batch_offset = [0, 8, 16, 24]
        batch_offset_tt_tensor = ttnn.as_tensor(
            torch.tensor(batch_offset, dtype=torch.int32).reshape(4, 1),
            dtype=ttnn.int32,
            device=mesh_device,
            mesh_mapper=ttnn.ShardTensor2dMesh(
                mesh_device=mesh_device, dims=(None, 0), mesh_shape=list(mesh_device.shape)
            ),
            layout=ttnn.TILE_LAYOUT,
            memory_config=ttnn.DRAM_MEMORY_CONFIG,
        )

        ##################################
        ##### Run the op
        ##################################
        tt_qkv_reduced = ttnn.experimental.all_reduce_async(
            tt_qkv,
            tt_intermediate_tensors[0],
            cluster_axis=cluster_axis,
            mesh_device=mesh_device,
            multi_device_global_semaphore=ccl_semaphore_handles[0],
            memory_config=output_mem_config,
            topology=ALL_GATHER_TOPOLOGY,
            num_links=num_links,
            subdevice_id=worker_sub_device_id,
        )  # [1, 1, 32, 1280]

        # Batch Slicing
        # 32 BS is split into 8 Mini BS across 4 devices
        ttnn.synchronize_device(mesh_device)

        (
            q_heads_pre_rot_1BQD,  # Shape([1, 8, 8, 128])
            k_heads_pre_rot_1BKD,  # Shape([1, 8, 1, 128])
            v_heads_1BKD,  # Shape([1, 8, 1, 128])
        ) = ttnn.experimental.nlp_create_qkv_heads_decode(
            tt_qkv_reduced,
            num_heads=8,
            num_kv_heads=1,
            memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
            overlap_qk_coregrid=False,
            batch_offset=batch_offset_tt_tensor,
            slice_size=8,
        )  # [1, 8, 8[32], 128], [1, 8, 1[32], 128], [1, 8, 1[32], 128]
        # q MemoryConfig(memory_layout=TensorMemoryLayout::HEIGHT_SHARDED,buffer_type=BufferType::L1,shard_spec=ShardSpec(grid={[(x=0,y=0) - (x=7,y=0)]},shape={32, 128},orientation=ShardOrientation::ROW_MAJOR,mode=ShardMode::PHYSICAL,physical_shard_shape=std::nullopt))
        # k MemoryConfig(memory_layout=TensorMemoryLayout::HEIGHT_SHARDED,buffer_type=BufferType::L1,shard_spec=ShardSpec(grid={[(x=0,y=1) - (x=7,y=1)]},shape={32, 128},orientation=ShardOrientation::ROW_MAJOR,mode=ShardMode::PHYSICAL,physical_shard_shape=std::nullopt))
        # v MemoryConfig(memory_layout=TensorMemoryLayout::HEIGHT_SHARDED,buffer_type=BufferType::L1,shard_spec=ShardSpec(grid={[(x=0,y=0) - (x=7,y=0)]},shape={32, 128},orientation=ShardOrientation::ROW_MAJOR,mode=ShardMode::PHYSICAL,physical_shard_shape=std::nullopt))
        # breakpoint()
        # After ConcatMesh2dToTensor
        # [1, 8, 8[32], 128] -> [8, 32, 8[32], 128]

        # Get non-distributed tensors
        q_non_distributed = ttnn.to_torch(
            q_heads_pre_rot_1BQD,
            # q_dummy,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        k_non_distributed = ttnn.to_torch(
            k_heads_pre_rot_1BKD,
            # k_dummy,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        v_non_distributed = ttnn.to_torch(
            v_heads_1BKD,
            # v_dummy,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # breakpoint()

        # input = [8, 4, 32, 1280]

        # reduced_input = [8, 32, 1280]
        reduced_input_tensor = input_tensor.sum(dim=1)

        # reduced_input_reshaped = [8, 32, 10, 128]
        reduced_input_tensor_reshaped = reduced_input_tensor.reshape(8, 32, 10, 128)

        # q_output = [8, 32, 8, 128]
        q_output_tensor = reduced_input_tensor_reshaped[:, :, :8, :]

        # k_output = [8, 32, 1, 128]
        k_output_tensor = reduced_input_tensor_reshaped[:, :, 8:9, :]

        # v_output = [8, 32, 1, 128]
        v_output_tensor = reduced_input_tensor_reshaped[:, :, 9:10, :]

        # Compare results
        assert_with_pcc(q_output_tensor, q_non_distributed, 0.9999)
        assert_with_pcc(k_output_tensor, k_non_distributed, 0.9999)
        assert_with_pcc(v_output_tensor, v_non_distributed, 0.9999)

    finally:
        if enable_persistent_fabric and teardown_persistent_fabric:
            mesh_device.reset_sub_device_stall_group()
            t1 = time()
            teardown_fabric_interface(mesh_device, wrap_fabric_around_mesh=WRAP_MESH, topology=ALL_GATHER_TOPOLOGY)
            t2 = time()
            logger.info(f"Teardown time: {t2 - t1}")


def run_all_reduce_qkv_heads_fuse_impl(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    enable_async=False,
):
    cluster_shape = (8, 4)

    create_persistent_fabric = True
    teardown_persistent_fabric = True
    enable_persistent_fabric = True

    # Use Async mode based on test input config
    mesh_device.enable_async(enable_async)

    ##################################
    ##### Set up fabric stuff
    ##################################
    compute_grid_size = mesh_device.compute_with_storage_grid_size()
    ccl_sub_device_crs = ttnn.CoreRangeSet(
        {ttnn.CoreRange(ttnn.CoreCoord(0, 0), ttnn.CoreCoord(compute_grid_size.x - 1, compute_grid_size.y - 1))}
    )
    worker_sub_device = ttnn.SubDevice(
        [
            ccl_sub_device_crs,
        ]
    )
    worker_sub_device_id = ttnn.SubDeviceId(0)
    sub_device_stall_group = [worker_sub_device_id]
    if create_persistent_fabric:
        mesh_sub_device_manager_id = create_and_load_sub_device_manager_with_fabric_interface(
            mesh_device,
            [worker_sub_device],
            0,
            0,
            enable_persistent_fabric,
            wrap_fabric_around_mesh=WRAP_MESH,
            topology=ALL_GATHER_TOPOLOGY,
        )
        mesh_device.set_sub_device_stall_group(sub_device_stall_group)

    # create global semaphore handles
    ccl_semaphore_handles = [create_global_semaphore_with_same_address(mesh_device, ccl_sub_device_crs, 0)]

    logger.info(f"Output shape: {output_shape}")

    try:
        ##################################
        ##### Set up input tensors/configs
        ##################################

        ##### FF2 Case #####
        M, N = output_shape[2:]
        N_per_shard = round_up(math.ceil(N / input_num_cores), ttnn.TILE_SIZE)
        output_N_per_shard = round_up(math.ceil(N / output_num_cores), ttnn.TILE_SIZE)
        input_shape = [*cluster_shape, M, N]  # [8, 4, 32, 1280]
        intermediate_shape = [*input_shape[:-1], N * cluster_shape[cluster_axis]]

        CORE_RANGE = [(x, y) for y in range(compute_grid_size.y) for x in range(compute_grid_size.x)]
        core_range_set = ttnn.CoreRangeSet(
            [
                ttnn.CoreRange(
                    ttnn.CoreCoord(x, y),
                    ttnn.CoreCoord(x, y),
                )
                for x, y in CORE_RANGE[:input_num_cores]
            ]
        )
        input_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                core_range_set,
                [M, N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        output_core_range_set = ttnn.num_cores_to_corerangeset(output_num_cores, ttnn.CoreCoord(8, 5), row_wise=True)
        output_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )
        intermediate_mem_config = ttnn.MemoryConfig(
            ttnn.TensorMemoryLayout.WIDTH_SHARDED,
            ttnn.BufferType.L1,
            ttnn.ShardSpec(
                output_core_range_set,
                [M, output_N_per_shard * cluster_shape[cluster_axis]],
                ttnn.ShardOrientation.ROW_MAJOR,
            ),
        )

        logger.info(f"Input shape: {input_shape[2:]}, Padded shape: {[M, N_per_shard * input_num_cores]}")
        input_tensor = torch.randn(input_shape)
        # input_tensor torch.Size([8, 4, 32, 1280])
        tt_qkv = ttnn.from_torch(
            input_tensor,
            device=mesh_device,
            layout=ttnn.TILE_LAYOUT,
            dtype=input_dtype,
            memory_config=input_mem_config,
            mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
        )  # [1, 1, 32, 1280]
        check_mesh_tensor_alloc(tt_qkv)

        intermediate_tensor = torch.zeros(intermediate_shape)
        tt_intermediate_tensors = [
            ttnn.from_torch(
                intermediate_tensor,
                device=mesh_device,
                layout=ttnn.TILE_LAYOUT,
                dtype=input_dtype,
                memory_config=intermediate_mem_config,
                mesh_mapper=ttnn.ShardTensor2dMesh(mesh_device, dims=(0, 1), mesh_shape=cluster_shape),
            )
        ]

        # Validate that the tensor is allocated in same location across devices
        check_mesh_tensor_alloc(tt_intermediate_tensors[0])

        # Select batch_offset with create_qkv_heads_decode instead of selection matmul
        batch_offset = [0, 8, 16, 24]
        batch_offset_tt_tensor = ttnn.as_tensor(
            torch.tensor(batch_offset, dtype=torch.int32).reshape(4, 1),
            dtype=ttnn.int32,
            device=mesh_device,
            mesh_mapper=ttnn.ShardTensor2dMesh(
                mesh_device=mesh_device, dims=(None, 0), mesh_shape=list(mesh_device.shape)
            ),
            layout=ttnn.TILE_LAYOUT,
            memory_config=ttnn.DRAM_MEMORY_CONFIG,
        )

        ##################################
        ##### Run the op
        ##################################
        # tt_qkv Shape([1, 1, 32, 1280])
        # tt_qkv_reduced Shape([1, 1, 32, 1280])
        # MemoryConfig(memory_layout=TensorMemoryLayout::WIDTH_SHARDED,buffer_type=BufferType::L1,shard_spec=ShardSpec(grid={[(x=0,y=0) - (x=7,y=4)]},shape={32, 32},orientation=ShardOrientation::ROW_MAJOR,mode=ShardMode::PHYSICAL,physical_shard_shape=std::nullopt))
        (
            tt_qkv_reduced,
            q_heads_pre_rot_1BQD,
            k_heads_pre_rot_1BKD,
            v_heads_1BKD,
        ) = ttnn.experimental.all_reduce_create_qkv_heads(
            tt_qkv,
            tt_intermediate_tensors[0],
            cluster_axis=cluster_axis,
            mesh_device=mesh_device,
            multi_device_global_semaphore=ccl_semaphore_handles[0],
            queue_id=0,
            num_heads=8,
            memory_config=output_mem_config,
            topology=ALL_GATHER_TOPOLOGY,
            num_links=num_links,
            subdevice_id=worker_sub_device_id,
            num_kv_heads=1,
            final_memory_config=ttnn.L1_HEIGHT_SHARDED_MEMORY_CONFIG,
            overlap_qk_coregrid=False,
            batch_offset=batch_offset_tt_tensor,
            slice_size=8,
        )  # [1, 1, 32, 1280]
        # breakpoint()
        # Batch Slicing
        # 32 BS is split into 8 Mini BS across 4 devices
        ttnn.synchronize_device(mesh_device)

        # Get non-distributed tensors
        q_non_distributed = ttnn.to_torch(
            q_heads_pre_rot_1BQD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        k_non_distributed = ttnn.to_torch(
            k_heads_pre_rot_1BKD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # [1, 8, 1[32], 128] -> [8, 32, 1[32], 128]
        v_non_distributed = ttnn.to_torch(
            v_heads_1BKD,
            mesh_composer=ttnn.ConcatMesh2dToTensor(
                mesh_device,
                dims=(0, 1),
                mesh_shape=cluster_shape,
            ),
        )
        # breakpoint()

        # input = [8, 4, 32, 1280]

        # reduced_input = [8, 32, 1280]
        reduced_input_tensor = input_tensor.sum(dim=1)

        # reduced_input_reshaped = [8, 32, 10, 128]
        reduced_input_tensor_reshaped = reduced_input_tensor.reshape(8, 32, 10, 128)

        # q_output = [8, 32, 8, 128]
        q_output_tensor = reduced_input_tensor_reshaped[:, :, :8, :]

        # k_output = [8, 32, 1, 128]
        k_output_tensor = reduced_input_tensor_reshaped[:, :, 8:9, :]

        # v_output = [8, 32, 1, 128]
        v_output_tensor = reduced_input_tensor_reshaped[:, :, 9:10, :]

        # Compare results
        assert_with_pcc(q_output_tensor, q_non_distributed, 0.9999)
        assert_with_pcc(k_output_tensor, k_non_distributed, 0.9999)
        assert_with_pcc(v_output_tensor, v_non_distributed, 0.9999)

    finally:
        if enable_persistent_fabric and teardown_persistent_fabric:
            mesh_device.reset_sub_device_stall_group()
            t1 = time()
            teardown_fabric_interface(mesh_device, wrap_fabric_around_mesh=WRAP_MESH, topology=ALL_GATHER_TOPOLOGY)
            t2 = time()
            logger.info(f"Teardown time: {t2 - t1}")


# Test 1: test_all_reduce_qkv_heads
@skip_for_grayskull("Requires eth connected devices to run")
@pytest.mark.timeout(900)
@pytest.mark.parametrize(
    "output_shape, cluster_axis, num_links, input_num_cores, output_num_cores",
    [
        ([1, 1, 32, 1280], 1, 3, 24, 10),  # QKV all reduce
    ],
)
@pytest.mark.parametrize(
    "input_dtype",
    [
        ttnn.bfloat16,
    ],
)
@pytest.mark.parametrize("enable_async", [True])
@pytest.mark.parametrize(
    "mesh_device",
    [
        (8, 4),
    ],
    indirect=True,
)
def test_all_reduce_qkv_heads(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    enable_async,
    use_program_cache,
):
    if len(mesh_device.get_devices()) != 32:
        pytest.skip("Not TG!")

    run_all_reduce_qkv_heads_impl(
        mesh_device,
        output_shape,
        cluster_axis,
        input_dtype,
        num_links,
        input_num_cores,
        output_num_cores,
        enable_async=enable_async,
    )


# Test 2: test_all_reduce_qkv_heads_fuse
@skip_for_grayskull("Requires eth connected devices to run")
@pytest.mark.timeout(900)
@pytest.mark.parametrize(
    "output_shape, cluster_axis, num_links, input_num_cores, output_num_cores",
    [
        ([1, 1, 32, 1280], 1, 3, 24, 10),  # QKV all reduce
    ],
)
@pytest.mark.parametrize(
    "input_dtype",
    [
        ttnn.bfloat16,
    ],
)
@pytest.mark.parametrize("enable_async", [True])
@pytest.mark.parametrize(
    "mesh_device",
    [
        (8, 4),
    ],
    indirect=True,
)
def test_all_reduce_qkv_heads_fuse(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    enable_async,
    use_program_cache,
):
    if len(mesh_device.get_devices()) != 32:
        pytest.skip("Not TG!")

    run_all_reduce_qkv_heads_fuse_impl(
        mesh_device,
        output_shape,
        cluster_axis,
        input_dtype,
        num_links,
        input_num_cores,
        output_num_cores,
        enable_async=enable_async,
    )


# Test 3: test_all_reduce_create_qkv_heads_perf
# Performance tests for pesudo-fused all reduce create qkv heads
@skip_for_grayskull("Requires eth connected devices to run")
@pytest.mark.parametrize("num_iters, warmup_iters", [[100, 10]])
@pytest.mark.parametrize("trace_mode", [True])
@pytest.mark.parametrize("enable_async", [True])
@pytest.mark.parametrize(
    "output_shape, cluster_axis, num_links, input_num_cores, output_num_cores",
    [
        ([1, 1, 32, 1280], 1, 3, 24, 10),  # QKV all reduce
    ],
)
@pytest.mark.parametrize(
    "input_dtype",
    [
        ttnn.bfloat16,
    ],
)
@pytest.mark.parametrize(
    "mesh_device",
    [
        (8, 4),
    ],
    indirect=True,
)
@pytest.mark.parametrize(
    "device_params",
    [{"trace_region_size": 23887872}],
    indirect=True,
)
def test_all_reduce_qkv_heads_perf(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    enable_async,
    use_program_cache,
    num_iters,
    warmup_iters,
    trace_mode,
):
    if len(mesh_device.get_devices()) != 32:
        pytest.skip("Not TG!")
    profiler = BenchmarkProfiler()
    run_all_reduce_qkv_heads_perf_impl(
        mesh_device,
        output_shape,
        cluster_axis,
        input_dtype,
        num_links,
        input_num_cores,
        output_num_cores,
        use_program_cache,
        enable_async=enable_async,
        num_iters=num_iters,
        warmup_iters=warmup_iters,
        trace_mode=trace_mode,
        profiler=profiler,
    )


# Test 4: test_all_reduce_create_qkv_heads_fuse_perf
# Performance tests for fused all reduce create qkv heads
@skip_for_grayskull("Requires eth connected devices to run")
@pytest.mark.parametrize("num_iters, warmup_iters", [[100, 10]])
@pytest.mark.parametrize("trace_mode", [True])
@pytest.mark.parametrize("enable_async", [True])
@pytest.mark.parametrize(
    "output_shape, cluster_axis, num_links, input_num_cores, output_num_cores",
    [
        ([1, 1, 32, 1280], 1, 3, 24, 10),  # QKV all reduce
    ],
)
@pytest.mark.parametrize(
    "input_dtype",
    [
        ttnn.bfloat16,
    ],
)
@pytest.mark.parametrize(
    "mesh_device",
    [
        (8, 4),
    ],
    indirect=True,
)
@pytest.mark.parametrize(
    "device_params",
    [{"trace_region_size": 23887872}],
    indirect=True,
)
def test_all_reduce_qkv_heads_fuse_perf(
    mesh_device,
    output_shape,
    cluster_axis,
    input_dtype,
    num_links,
    input_num_cores,
    output_num_cores,
    enable_async,
    use_program_cache,
    num_iters,
    warmup_iters,
    trace_mode,
):
    if len(mesh_device.get_devices()) != 32:
        pytest.skip("Not TG!")
    profiler = BenchmarkProfiler()
    run_all_reduce_qkv_heads_fuse_perf_impl(
        mesh_device,
        output_shape,
        cluster_axis,
        input_dtype,
        num_links,
        input_num_cores,
        output_num_cores,
        use_program_cache,
        enable_async=enable_async,
        num_iters=num_iters,
        warmup_iters=warmup_iters,
        trace_mode=trace_mode,
        profiler=profiler,
    )
